{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkrQC7Y2NIxg"
      },
      "outputs": [],
      "source": [
        "# 1. Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score, roc_auc_score\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# 2. Load data\n",
        "\n",
        "df = pd.read_csv(\"/content/training-data - Copy - Copy.csv\")\n",
        "\n",
        "\n",
        "# 3. Feature engineering\n",
        "\n",
        "df['Lesion-volume-log'] = np.log1p(df['Lesion-volume'])\n",
        "df['NIHSS_x_Age'] = df['NIHSS'] * df['Age']\n",
        "df['LesionVol_x_Side'] = df['Lesion-volume-log'] * df['Lesion side']\n",
        "df['Glucose_x_Lesion'] = df['Glucose'] * df['Lesion-volume-log']\n",
        "\n",
        "manual_features = [\n",
        "    'Lesion-volume-log', 'NIHSS', 'Age', 'Lesion side', 'Glucose',\n",
        "    'Previous Stroke', 'BMI', 'Triglycerides', 'Obesity',\n",
        "    'Creatinine', 'Sex', 'Systolic',\n",
        "    'NIHSS_x_Age', 'LesionVol_x_Side', 'Glucose_x_Lesion'\n",
        "]\n",
        "categorical_feats = ['Lesion side', 'Previous Stroke', 'Sex']\n",
        "\n",
        "# Drop samples missing mRS\n",
        "df = df.dropna(subset=['90days-mRS'])\n",
        "\n",
        "X = df[manual_features]\n",
        "y_mRS = df['90days-mRS'].astype(int)\n",
        "y_type = df['lesion type'].astype(int)\n",
        "\n",
        "cont_feats = [f for f in manual_features if f not in categorical_feats]\n",
        "\n",
        "\n",
        "# 4. XGBoost parameters & Monotonic Constraints\n",
        "\n",
        "# Define monotonic constraints based on feature order\n",
        "monotonic_constraints = [\n",
        "    +1, # Lesion-volume-log\n",
        "    +1, # NIHSS\n",
        "    +1, # Age\n",
        "    0,  # Lesion side\n",
        "    +1, # Glucose\n",
        "    0,  # Previous Stroke\n",
        "    0,  # BMI\n",
        "    0,  # Triglycerides\n",
        "    0,  # Obesity\n",
        "    +1, # Creatinine\n",
        "    0,  # Sex\n",
        "    +1, # Systolic\n",
        "    +1, # NIHSS_x_Age\n",
        "    0,  # LesionVol_x_Side\n",
        "    +1, # Glucose_x_Lesion\n",
        "]\n",
        "\n",
        "params_mrs = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'learning_rate': 0.018,\n",
        "    'max_depth': 4,\n",
        "    'n_estimators': 5000,\n",
        "    'eval_metric': 'logloss',\n",
        "    'tree_method': 'hist',\n",
        "    'seed': 42,\n",
        "    # *** ADDED MONOTONIC CONSTRAINTS ***\n",
        "    'monotone_constraints': tuple(monotonic_constraints)\n",
        "}\n",
        "\n",
        "params_type = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'learning_rate': 0.02,\n",
        "    'max_depth': 5,\n",
        "    'n_estimators': 3000,\n",
        "    'eval_metric': 'logloss',\n",
        "    'tree_method': 'hist',\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "\n",
        "# 5. Functions (Dynamic Weights & QWK Tuning)\n",
        "\n",
        "def train_ordinal_xgb(X_train, y_train, X_val, y_val, params):\n",
        "    \"\"\"Trains the mRS head with DYNAMIC scale_pos_weight for each ordinal cut.\"\"\"\n",
        "    n_classes = int(y_train.max()) + 1\n",
        "    preds_val = np.zeros((X_val.shape[0], n_classes-1))\n",
        "\n",
        "    for k in range(n_classes-1):\n",
        "        y_bin_train = (y_train > k).astype(int)\n",
        "        y_bin_val = (y_val > k).astype(int)\n",
        "\n",
        "        current_params = params.copy()\n",
        "\n",
        "        # DYNAMIC SCALE_POS_WEIGHT (MRS HEAD)\n",
        "        pos_count = np.sum(y_bin_train)\n",
        "        neg_count = len(y_bin_train) - pos_count\n",
        "\n",
        "        if pos_count > 0 and neg_count > 0:\n",
        "            current_params['scale_pos_weight'] = neg_count / pos_count\n",
        "\n",
        "        dtrain = xgb.DMatrix(X_train, label=y_bin_train)\n",
        "        dvalid = xgb.DMatrix(X_val, label=y_bin_val)\n",
        "\n",
        "        model = xgb.train(\n",
        "            current_params,\n",
        "            dtrain,\n",
        "            num_boost_round=params['n_estimators'],\n",
        "            evals=[(dvalid, 'valid')],\n",
        "            early_stopping_rounds=50,\n",
        "            verbose_eval=False\n",
        "        )\n",
        "        preds_val[:, k] = model.predict(dvalid)\n",
        "    return preds_val\n",
        "\n",
        "def train_type_xgb(X_train, y_train, X_val, y_val, params):\n",
        "    \"\"\"Trains the Lesion Type head with DYNAMIC scale_pos_weight.\"\"\"\n",
        "    current_params = params.copy()\n",
        "\n",
        "    # DYNAMIC SCALE_POS_WEIGHT (TYPE HEAD)\n",
        "    pos_count = np.sum(y_train)\n",
        "    neg_count = len(y_train) - pos_count\n",
        "\n",
        "    if pos_count > 0 and neg_count > 0:\n",
        "        current_params['scale_pos_weight'] = neg_count / pos_count\n",
        "\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "    dvalid = xgb.DMatrix(X_val, label=y_val)\n",
        "\n",
        "    model = xgb.train(\n",
        "        current_params,\n",
        "        dtrain,\n",
        "        num_boost_round=params['n_estimators'],\n",
        "        evals=[(dvalid, 'valid')],\n",
        "        early_stopping_rounds=50,\n",
        "        verbose_eval=False\n",
        "    )\n",
        "    return model.predict(dvalid)\n",
        "\n",
        "def apply_thresholds(pred_matrix, thresholds):\n",
        "    \"\"\"Counts the number of exceeded probability thresholds to get the mRS prediction.\"\"\"\n",
        "    n_samples, n_preds = pred_matrix.shape\n",
        "    final_preds = np.zeros(n_samples, dtype=int)\n",
        "    for i in range(n_samples):\n",
        "        score = 0\n",
        "        for k in range(n_preds):\n",
        "            if pred_matrix[i, k] >= thresholds[k]:\n",
        "                score += 1\n",
        "        final_preds[i] = score\n",
        "    return final_preds\n",
        "\n",
        "def tune_thresholds(y_true, prob_matrix):\n",
        "    \"\"\"Uses Powell minimization to find thresholds that maximize QWK (Minimize -QWK).\"\"\"\n",
        "    n_cuts = prob_matrix.shape[1]\n",
        "    initial_thresholds = np.full(n_cuts, 0.5)\n",
        "\n",
        "    def loss(thresholds):\n",
        "        preds = apply_thresholds(prob_matrix, thresholds)\n",
        "        return -cohen_kappa_score(y_true, preds, weights='quadratic')\n",
        "\n",
        "    # Use Powell method with bounds [0, 1] for robust threshold optimization\n",
        "    result = minimize(loss, initial_thresholds, method='Powell', bounds=[(0, 1)]*n_cuts)\n",
        "    return result.x\n",
        "\n",
        "\n",
        "# 6. 5-Fold Cross-Validation (Leakage Fixed)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "oof_mrs = np.zeros((X.shape[0], 6))\n",
        "oof_type = np.zeros(X.shape[0])\n",
        "\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "scaler = RobustScaler()\n",
        "impute_scale_cols = cont_feats\n",
        "\n",
        "for train_idx, val_idx in kf.split(X):\n",
        "    # Use .copy() to prevent SettingWithCopyWarning\n",
        "    Xtr, Xv = X.iloc[train_idx].copy(), X.iloc[val_idx].copy()\n",
        "    ytr_mRS, yv_mRS = y_mRS.iloc[train_idx], y_mRS.iloc[val_idx]\n",
        "    ytr_type, yv_type = y_type.iloc[train_idx], y_type.iloc[val_idx]\n",
        "\n",
        "    # --- LEAKAGE FIX ZONE: Imputation and Scaling INSIDE THE CV LOOP ---\n",
        "    # 1. Imputation (Fit on Train, Transform All)\n",
        "    Xtr.loc[:, impute_scale_cols] = imputer.fit_transform(Xtr[impute_scale_cols])\n",
        "    Xv.loc[:, impute_scale_cols] = imputer.transform(Xv[impute_scale_cols])\n",
        "\n",
        "    # 2. Scaling (Fit on Train, Transform All)\n",
        "    Xtr.loc[:, impute_scale_cols] = scaler.fit_transform(Xtr[impute_scale_cols])\n",
        "    Xv.loc[:, impute_scale_cols] = scaler.transform(Xv[impute_scale_cols])\n",
        "    # --- END LEAKAGE FIX ZONE ---\n",
        "\n",
        "    # Train ordinal mRS (FIXED CALL: passing yv_mRS)\n",
        "    oof_mrs[val_idx] = train_ordinal_xgb(Xtr, ytr_mRS, Xv, yv_mRS, params_mrs)\n",
        "\n",
        "    # Train binary Type\n",
        "    oof_type[val_idx] = train_type_xgb(Xtr, ytr_type, Xv, yv_type, params_type)\n",
        "\n",
        "\n",
        "# 7. Threshold Tuning & Metrics\n",
        "\n",
        "thresholds = tune_thresholds(y_mRS.values, oof_mrs)\n",
        "final_pred_mrs = apply_thresholds(oof_mrs, thresholds)\n",
        "# Assuming 0.5 threshold for Type for simplicity (Tuning is preferred)\n",
        "final_pred_type = (oof_type > 0.5).astype(int)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FINAL METRICS (XGBOOST DUAL-HEAD: MONOTONIC + DYNAMIC WEIGHTS)\")\n",
        "print(\"=\"*50)\n",
        "print(f\"FINAL OOF QWK (mRS) = {cohen_kappa_score(y_mRS, final_pred_mrs, weights='quadratic'):.4f}\")\n",
        "print(f\"FINAL OOF ACC (Type) = {accuracy_score(y_type, final_pred_type):.4f}\")\n",
        "print(f\"Binary Type ROC-AUC = {roc_auc_score(y_type, oof_type):.4f}\")\n",
        "\n",
        "try:\n",
        "    # Calculation for mRS multi-class ROC-AUC\n",
        "    mrs_auc_approx = roc_auc_score(y_mRS, oof_mrs.mean(axis=1), average='weighted')\n",
        "    print(f\"mRS multi-class ROC-AUC (Approx): {mrs_auc_approx:.4f}\")\n",
        "except Exception as e:\n",
        "    print(f\"mRS AUC could not be computed easily. Error: {e}\")\n",
        "\n",
        "print(\"\\nBest Thresholds (mRS k=0 to 5):\", np.round(thresholds, 3))\n",
        "print(\"=\"*50)"
      ]
    }
  ]
}